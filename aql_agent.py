import os
import json
import time
import re
import networkx as nx
import nx_arangodb as nxadb
import pandas as pd
import matplotlib.pyplot as plt
from typing import Annotated, Dict, TypedDict, Any, Optional, List
from datetime import datetime
from pydantic import BaseModel

# LangChain and LangGraph imports
from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain.callbacks.base import BaseCallbackHandler
from langchain.agents import (
    AgentExecutor,
    create_openai_tools_agent,
)
import asyncio
# ArangoDB imports
from arango import ArangoClient
from tools import *
from callback import *
from settings import *
from dotenv import load_dotenv
load_dotenv()

# os.environ["LANGSMITH_TRACING"] = "true"
# os.environ["LANGSMITH_ENDPOINT"] = "https://api.smith.langchain.com"
# os.environ["LANGSMITH_PROJECT"] = "arangodb-cugraph"
# os.environ["LANGSMITH_API_KEY"] = os.getenv("LANGSMITH_API_KEY")



# Tools for each specialized agent
AQL_QUERY_TOOLS = [text_to_aql_to_text]

class AgentState(TypedDict):
    messages: list  
    context: Dict
    internal_state: Dict
    callback: Any


def create_llm():
    """Create a standard LLM for all agents"""
    return ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.1
    )


def create_judge_llm():
    """Create a Judge LLM for evaluating the agent responses"""
    return ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.1
    )


def evaluate_with_judge(response: str, expected_answer: str):
    """
    Evaluates the agent's response using Judge LLM.
    
    Args:
        response: The output generated by the agent.
        expected_answer: The correct or expected answer for comparison.
    
    Returns:
        Evaluation result (e.g., score, feedback).
    """
    
    # Define the evaluation prompt for the Judge LLM
    evaluation_prompt = f"""
    You are an expert medical data evaluator specializing in ArangoDB graph queries and their medical interpretations. Your task is to evaluate the response generated by an AI agent that converts a medical question into an AQL query, executes it, and interprets the results. 

    Please follow these guidelines:

    1. **AQL Query Validation**:
        - Check if the agent correctly translated the natural language question into an AQL query. Was the AQL query appropriate for the task?
        - Ensure the query is syntactically correct and uses the correct database schema and field names.
        - Was the query optimized (e.g., no unnecessary joins or filtering) to retrieve the correct data efficiently?

    2. **Medical Accuracy**:
        - Ensure the interpretation of the query result is accurate from a medical standpoint.
        - Did the agent provide a correct and medically meaningful interpretation of the query result (e.g., average age, medical conditions, etc.)?
        - Was the response medically relevant and easy to understand for healthcare professionals?

    3. **Clarity and Structure**:
        - Was the response clear and structured, following proper medical terminology?
        - Did the agent provide adequate context or explanations to ensure a healthcare professional would understand the results?
        - Did the agent avoid jargon that might confuse non-technical medical users?

    4. **Feedback**:
        - If the agentâ€™s response is incorrect or incomplete, provide detailed feedback on what went wrong.
        - Suggest improvements in terms of both query formulation and interpretation.

    5. **Scoring**:
        - Provide a score between 1 and 10, where 10 means the response was perfect, and 1 means the response was completely incorrect or misleading.

    Please provide the score, and a detailed explanation for your evaluation.

    ---

    Agent's Response: {response}
    Expected Answer: {expected_answer}
    """
    
    judge_llm = create_judge_llm()
    
    # Get the evaluation result from the Judge LLM
    evaluation_result = judge_llm.invoke({"messages": [("human", evaluation_prompt)]})
    
    if evaluation_result["messages"]:
        return evaluation_result["messages"][-1].content
    else:
        return "No evaluation generated"


def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str, max_iterations: int = 2, max_execution_time: int = 120) -> AgentExecutor:
    """
    Creates a LangGraph react agent using the specified ChatOpenAI model, tools, and system prompt.
    
    Args:
        llm: LLM to be used to create the agent
        tools: List of tools to be given to the agent
        system_prompt: System prompt to be used in the agent
        max_iterations: Maximum number of iterations (will be converted to recursion_limit)
        max_execution_time: Maximum execution time in seconds
    """
    def _modify_state_messages(state: AgentState):
        # Add system prompt and keep existing messages
        return [("system", system_prompt)] + state["messages"]
    
    # Create the react agent
    agent = create_react_agent(llm, tools, prompt=_modify_state_messages)
    
    # Set recursion limit (LangGraph uses 2 steps per iteration + 1)
    agent.recursion_limit = 2 * max_iterations + 1
    
    # Set timeout for each step
    agent.step_timeout = max_execution_time
    
    return agent


system_prompt = f"""
You are an expert medical data analyst specializing in ArangoDB graph queries.
        
        Your role is to:
        1. Convert natural language medical questions into precise AQL queries AND use the provided AQL_QUERY_TOOLS tools for query execution
        2. Execute these queries against the SYNTHEA_P100 database
        3. Interpret the results in a medically meaningful way
        4. Provide clear, structured responses that medical professionals can use
        
        Database schema:
        {json.dumps(graph_schema, indent=2)}
        
        Important guidelines:
        1. ALWAYS utilize the provided AQL_QUERY_TOOLS tools for query execution
        2. Before executing any query, validate that all required tools are accessible
        
        
        Always use proper medical terminology and provide context for your findings.
"""
llm = create_llm()

def aql_query_node(state):
    """
    Handles fundamental analysis and financial metrics using tools from tools.py
    """
 
    try:
        aql_agent = create_agent(
            llm, 
            AQL_QUERY_TOOLS, 
            system_prompt,
            max_iterations=2,
            max_execution_time=120
        )
        
        state["callback"].write_agent_name("AQL Query Agent ðŸ“Š")
        
        # Stream mode will give us intermediate steps
        chunks = []
        for chunk in aql_agent.stream(
            {"messages": state["messages"]},
            {"callbacks": [state["callback"]]},
            stream_mode="updates"  # This gives us intermediate steps
        ):
            chunks.append(chunk)
            
        # Get final state from chunks
        final_messages = chunks[-1].get("messages", []) if chunks else []
        
        # Update state with agent's response
        state["messages"] = final_messages
        
        # Store internal state
        state["aql_query_agent_internal_state"]["agent_executor_tools"] = {
            tool.name: 0 for tool in AQL_QUERY_TOOLS
        }
        state["aql_query_agent_internal_state"]["full_response"] = {
            "messages": final_messages,
            "intermediate_steps": chunks[:-1] if chunks else []  # All but last chunk are intermediate steps
        }
        
    except TimeoutError:
        # Handle timeout
        state["messages"].append(
            AIMessage(content="Agent stopped due to timeout.")
        )
    except Exception as e:
        # Handle other errors
        state["messages"].append(
            AIMessage(content=f"Agent encountered an error: {str(e)}")
        )
    
    return state


def run_aql_agent(question: str, expected_answer: str, current_date: str = None):
    """
    Runs the financial agent with the given question and evaluates the result.
    
    Args:
        question: The user's question
        expected_answer: The correct or expected answer for comparison
        current_date: Optional date context
    """
    # Initialize state with datetime object
    if current_date and isinstance(current_date, str):
        current_date = datetime.strptime(current_date, "%Y-%m-%d")
    else:
        current_date = datetime.now()

    initial_state = {
        "messages": [("human", question)],
        "user_input": question,
        "callback": CustomConsoleCallbackHandler(),
        "aql_query_agent_internal_state": {}
    }
    
    # Run the agent
    try:
        # Create agent directly like in the other methods
        aql_agent = create_agent(
            llm,
            AQL_QUERY_TOOLS,
            system_prompt,
            max_iterations=2,
            max_execution_time=120
        )
        
        result = aql_agent.invoke(
            {"messages": initial_state["messages"]},
            {"callbacks": [initial_state["callback"]]},
        )
        
        # Get the last message content
        if result["messages"] and len(result["messages"]) > 0:
            agent_response = result["messages"][-1].content
        else:
            agent_response = "No response generated"
        
        # Evaluate the response using Judge LLM
        evaluation = evaluate_with_judge(agent_response, expected_answer)
        
        return agent_response, evaluation
        
    except Exception as e:
        return f"Error running agent: {str(e)}", None


# Example usage:
if __name__ == "__main__":
    question = "What is the average age of patients in the database?"
    expected_answer = "The average age of patients in the database is 45."  # Replace with the correct expected answer
    
    agent_response, evaluation = run_aql_agent(question, expected_answer)
    
    print(f"Agent's Response: {agent_response}")
    print(f"Evaluation: {evaluation}")
